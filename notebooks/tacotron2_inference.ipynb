{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Virtualenv\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"../\")\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_tts.inference import AutoConfig\n",
    "from tensorflow_tts.inference import TFAutoModel\n",
    "from tensorflow_tts.inference import AutoProcessor\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"tensorspeech/tts-tacotron2-ljspeech-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"i love you so much.\"\n",
    "input_ids = processor.text_to_sequence(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-tacotron2-ljspeech-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2.setup_window(win_front=6, win_back=6)\n",
    "tacotron2.setup_maximum_iterations(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model into pb and do inference. Note that signatures should be a tf.function with input_signatures.\n",
    "tf.saved_model.save(tacotron2, \"./test_saved\", signatures=tacotron2.inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = tf.saved_model.load(\"./test_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Unless you work on a ship, it's unlikely that you use the word boatswain in everyday conversation, so it's understandably a tricky one. The word - which refers to a petty officer in charge of hull maintenance is not pronounced boats-wain Rather, it's bo-sun to reflect the salty pronunciation of sailors, as The Free Dictionary explains.\"\n",
    "input_ids = processor.text_to_sequence(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, mel_outputs, stop_token_prediction, alignment_history = tacotron2.inference(\n",
    "        tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "        tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "        tf.convert_to_tensor([0], dtype=tf.int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(f'Alignment steps')\n",
    "im = ax.imshow(\n",
    "    alignment_history[0].numpy(),\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    interpolation='none')\n",
    "fig.colorbar(im, ax=ax)\n",
    "xlabel = 'Decoder timestep'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel('Encoder timestep')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs = tf.reshape(mel_outputs, [-1, 80]).numpy()\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_title(f'Predicted Mel-after-Spectrogram')\n",
    "im = ax1.imshow(np.rot90(mel_outputs), aspect='auto', interpolation='none')\n",
    "fig.colorbar(mappable=im, shrink=0.65, orientation='horizontal', ax=ax1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let inference other input to check dynamic shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The Commission further recommends that the Secret Service coordinate its planning as closely as possible with all of the Federal agencies from which it receives information.\"\n",
    "input_ids = processor.text_to_sequence(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, mel_outputs, stop_token_prediction, alignment_history = tacotron2.inference(\n",
    "        tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "        tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "        tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(f'Alignment steps')\n",
    "im = ax.imshow(\n",
    "    alignment_history[0].numpy(),\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    interpolation='none')\n",
    "fig.colorbar(im, ax=ax)\n",
    "xlabel = 'Decoder timestep'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel('Encoder timestep')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs = tf.reshape(mel_outputs, [-1, 80]).numpy()\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_title(f'Predicted Mel-after-Spectrogram')\n",
    "im = ax1.imshow(np.rot90(mel_outputs), aspect='auto', interpolation='none')\n",
    "fig.colorbar(mappable=im, shrink=0.65, orientation='horizontal', ax=ax1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
