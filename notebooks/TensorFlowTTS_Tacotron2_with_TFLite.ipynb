{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Do75nZO17R_g"
   },
   "source": [
    "Author : [jaeyoo@](https://github.com/jaeyoo), [khanhlvg@](https://github.com/khanhlvg), [abattery@](https://github.com/abattery), [thaink@](https://github.com/thaink) (Google Research)\n",
    "\n",
    "Created : 2020-06-30 KST\n",
    "\n",
    "Last updated : 2020-07-04 KST\n",
    "\n",
    "-----\n",
    "Change logs\n",
    "* 2020-07-04 KST : Update notebook with the lastest TensorflowTTS repo.\n",
    " * compatible with https://github.com/TensorSpeech/TensorflowTTS/pull/83\n",
    "* 2020-07-02 KST : Third implementation (outputs : `tacotron2.tflite`) \n",
    " * **varied-length** input tensor, **varied-length** output tensor\n",
    "-----\n",
    "\n",
    "**Status** : successfully converted (`tacotron2.tflite`)\n",
    "\n",
    "**Disclaimer** \n",
    "-  This colab doesn't care about the latency, so it compressed the model with quantization. (129 MB -> 33 MB)\n",
    "- The TFLite file doesn't have LJSpeechProcessor. So you need to run it before feeding input vectors.\n",
    "- `tf-nightly>=2.4.0-dev20200630`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5aF0cRBv57s"
   },
   "source": [
    "# Generate voice with Tacotron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "3kDDtdfy-Fcf",
    "outputId": "c562941a-b89f-40aa-dbcb-c71ff93ec500"
   },
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "EHHcYEUyon5W",
    "outputId": "55c16833-e745-4fdb-b12d-378fe7b2849d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_tts.inference import AutoProcessor\n",
    "from tensorflow_tts.inference import AutoConfig\n",
    "from tensorflow_tts.inference import TFAutoModel\n",
    "\n",
    "from IPython.display import Audio\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBr1A7MBSm6u"
   },
   "outputs": [],
   "source": [
    "# initialize melgan model\n",
    "melgan = TFAutoModel.from_pretrained(\"tensorspeech/tts-melgan-ljspeech-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "n-eiPi6Vmf47",
    "outputId": "f0c5e414-d126-4565-a9b3-bcfa2ca747ee"
   },
   "outputs": [],
   "source": [
    "# initialize Tacotron2 model.\n",
    "tacotron2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-tacotron2-ljspeech-en\", enable_tflite_convertible=True)\n",
    "\n",
    "# Newly added :\n",
    "tacotron2.setup_window(win_front=6, win_back=6)\n",
    "tacotron2.setup_maximum_iterations(3000)\n",
    "\n",
    "tacotron2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38xzKgqgwbLl"
   },
   "source": [
    "# Convert to TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3eBgJr1CfqF"
   },
   "outputs": [],
   "source": [
    "# Concrete Function\n",
    "tacotron2_concrete_function = tacotron2.inference_tflite.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d9CUR0UD8O9w",
    "outputId": "93780e00-091f-4589-c688-abeb0b19eab1"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
    "    [tacotron2_concrete_function]\n",
    ")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IjLkV0wlIVq1",
    "outputId": "7085e0d8-844a-42bb-fc49-b777fa3beb03"
   },
   "outputs": [],
   "source": [
    "# Save the TF Lite model.\n",
    "with open('tacotron2.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "print('Model size is %f MBs.' % (len(tflite_model) / 1024 / 1024.0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "gLoUH69hJkIK",
    "outputId": "fadbe364-c346-492f-dd89-644382b454eb"
   },
   "outputs": [],
   "source": [
    "# Download the TF Lite model\n",
    "# from google.colab import files\n",
    "# files.download('tacotron2.tflite') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WqL_NEbtL5K"
   },
   "source": [
    "# Inference from TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjNnqWlItLXi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path='tacotron2.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data.\n",
    "def prepare_input(input_ids):\n",
    "  return (tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "          tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "          tf.convert_to_tensor([0], dtype=tf.int32))\n",
    "  \n",
    "# Test the model on random input data.\n",
    "def infer(input_text):\n",
    "  processor = LJSpeechProcessor(None, \"english_cleaners\")\n",
    "  input_ids = processor.text_to_sequence(input_text.lower())\n",
    "  input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)  # eos.\n",
    "  interpreter.resize_tensor_input(input_details[0]['index'], \n",
    "                                  [1, len(input_ids)])\n",
    "  interpreter.allocate_tensors()\n",
    "  input_data = prepare_input(input_ids)\n",
    "  for i, detail in enumerate(input_details):\n",
    "    print(detail)\n",
    "    input_shape = detail['shape']\n",
    "    interpreter.set_tensor(detail['index'], input_data[i])\n",
    "\n",
    "  interpreter.invoke()\n",
    "\n",
    "  # The function `get_tensor()` returns a copy of the tensor data.\n",
    "  # Use `tensor()` in order to get a pointer to the tensor.\n",
    "  return (interpreter.get_tensor(output_details[0]['index']),\n",
    "          interpreter.get_tensor(output_details[1]['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "dRgCO2UfdrBe",
    "outputId": "12f39cb3-2ce7-4b74-9142-bbca3b8d2373"
   },
   "outputs": [],
   "source": [
    "input_text = \"Recent research at Harvard has shown meditating\\\n",
    "for as little as 8 weeks, can actually increase the grey matter in the \\\n",
    "parts of the brain responsible for emotional regulation, and learning.\"\n",
    "\n",
    "decoder_output_tflite, mel_output_tflite = infer(input_text)\n",
    "audio_before_tflite = melgan(decoder_output_tflite)[0, :, 0]\n",
    "audio_after_tflite = melgan(mel_output_tflite)[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "vajrYnWAX31f",
    "outputId": "aefc25c4-3985-4325-a4dd-87ed2db10f3b"
   },
   "outputs": [],
   "source": [
    "Audio(data=audio_before_tflite, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "-eJ5QGc5X_Tc",
    "outputId": "2da7480d-a602-444c-f286-26a35730b1fa"
   },
   "outputs": [],
   "source": [
    "Audio(data=audio_after_tflite, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "iht1FDZUd0Ig",
    "outputId": "063f32d6-6d0a-46da-f264-9b6ea4b39ed3"
   },
   "outputs": [],
   "source": [
    "input_text = \"I love TensorFlow Lite converted Tacotron 2.\"\n",
    "\n",
    "decoder_output_tflite, mel_output_tflite = infer(input_text)\n",
    "audio_before_tflite = melgan(decoder_output_tflite)[0, :, 0]\n",
    "audio_after_tflite = melgan(mel_output_tflite)[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "ZJVtr-D3d6rr",
    "outputId": "2ebad60a-ec4f-4ae8-c013-65e3e6baa259"
   },
   "outputs": [],
   "source": [
    "Audio(data=audio_before_tflite, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "mBU2Zdl1d8ZI",
    "outputId": "00cbd782-b763-4d17-ec1d-12ad713f6e1f"
   },
   "outputs": [],
   "source": [
    "Audio(data=audio_after_tflite, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlowTTS - Tacotron2 with TFLite",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
